{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7920 images belonging to 5 classes.\n",
      "Found 1980 images belonging to 5 classes.\n",
      "Found 100 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Directories\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Data generator for training data\n",
    "\n",
    "# Data generator for training data with validation split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=40,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)  # 20% validation split\n",
    "\n",
    "# Separate generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')  # Specify 'training' subset\n",
    "\n",
    "# Separate generator for validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')  # Specify 'validation' subset\n",
    "\n",
    "\n",
    "\n",
    "# Data generator for test data\n",
    "test_files = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))]\n",
    "\n",
    "# Create a DataFrame with the filenames\n",
    "test_df = pd.DataFrame({\"Filename\": test_files})\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='Filename',\n",
    "    y_col=None,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######ALEX NET\n",
    "\n",
    "import keras\n",
    "\n",
    "model=keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5,activation='softmax')  \n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 128)       46592     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 54, 54, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 9, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 9, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 9, 9, 256)         65792     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 9, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 256)         65792     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 9, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,842,373\n",
      "Trainable params: 6,840,069\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']    \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/50\n",
    "248/248 [==============================] - 68s 271ms/step - loss: 1.8903 - accuracy: 0.4037 - val_loss: 1.6548 - val_accuracy: 0.2753\n",
    "Epoch 2/50\n",
    "248/248 [==============================] - 66s 266ms/step - loss: 1.2663 - accuracy: 0.4879 - val_loss: 2.0899 - val_accuracy: 0.2702\n",
    "Epoch 3/50\n",
    "248/248 [==============================] - 68s 272ms/step - loss: 1.1476 - accuracy: 0.5307 - val_loss: 1.4332 - val_accuracy: 0.3747\n",
    "Epoch 4/50\n",
    "248/248 [==============================] - 67s 269ms/step - loss: 1.1153 - accuracy: 0.5525 - val_loss: 1.2825 - val_accuracy: 0.4364\n",
    "Epoch 5/50\n",
    "248/248 [==============================] - 69s 277ms/step - loss: 1.0653 - accuracy: 0.5794 - val_loss: 1.2759 - val_accuracy: 0.4601\n",
    "Epoch 6/50\n",
    "248/248 [==============================] - 70s 282ms/step - loss: 1.0196 - accuracy: 0.6003 - val_loss: 1.3848 - val_accuracy: 0.4520\n",
    "Epoch 7/50\n",
    "248/248 [==============================] - 76s 307ms/step - loss: 1.0055 - accuracy: 0.6130 - val_loss: 1.1646 - val_accuracy: 0.5258\n",
    "Epoch 8/50\n",
    "248/248 [==============================] - 67s 269ms/step - loss: 0.9902 - accuracy: 0.6158 - val_loss: 1.0996 - val_accuracy: 0.5545\n",
    "Epoch 9/50\n",
    "248/248 [==============================] - 69s 277ms/step - loss: 0.9713 - accuracy: 0.6360 - val_loss: 1.2617 - val_accuracy: 0.5086\n",
    "Epoch 10/50\n",
    "248/248 [==============================] - 73s 295ms/step - loss: 0.9392 - accuracy: 0.6424 - val_loss: 1.1390 - val_accuracy: 0.5763\n",
    "Epoch 11/50\n",
    "248/248 [==============================] - 70s 279ms/step - loss: 0.9220 - accuracy: 0.6516 - val_loss: 1.0941 - val_accuracy: 0.5591\n",
    "Epoch 12/50\n",
    "248/248 [==============================] - 72s 289ms/step - loss: 0.8930 - accuracy: 0.6630 - val_loss: 1.0609 - val_accuracy: 0.5864\n",
    "Epoch 13/50\n",
    "248/248 [==============================] - 72s 288ms/step - loss: 0.8687 - accuracy: 0.6764 - val_loss: 1.1963 - val_accuracy: 0.4965\n",
    "Epoch 14/50\n",
    "248/248 [==============================] - 69s 277ms/step - loss: 0.8469 - accuracy: 0.6821 - val_loss: 1.0346 - val_accuracy: 0.5970\n",
    "Epoch 15/50\n",
    "248/248 [==============================] - 72s 291ms/step - loss: 0.8299 - accuracy: 0.6923 - val_loss: 0.9871 - val_accuracy: 0.6167\n",
    "Epoch 16/50\n",
    "248/248 [==============================] - 68s 273ms/step - loss: 0.7956 - accuracy: 0.6996 - val_loss: 0.9549 - val_accuracy: 0.6465\n",
    "Epoch 17/50\n",
    "248/248 [==============================] - 69s 277ms/step - loss: 0.7820 - accuracy: 0.7152 - val_loss: 1.0316 - val_accuracy: 0.6101\n",
    "Epoch 18/50\n",
    "248/248 [==============================] - 69s 276ms/step - loss: 0.7646 - accuracy: 0.7160 - val_loss: 0.9308 - val_accuracy: 0.6460\n",
    "Epoch 19/50\n",
    "248/248 [==============================] - 67s 267ms/step - loss: 0.7525 - accuracy: 0.7245 - val_loss: 0.9162 - val_accuracy: 0.6429\n",
    "Epoch 20/50\n",
    "248/248 [==============================] - 66s 267ms/step - loss: 0.7295 - accuracy: 0.7362 - val_loss: 0.9400 - val_accuracy: 0.6571\n",
    "Epoch 21/50\n",
    "248/248 [==============================] - 85s 342ms/step - loss: 0.7235 - accuracy: 0.7384 - val_loss: 1.0224 - val_accuracy: 0.6157\n",
    "Epoch 22/50\n",
    "248/248 [==============================] - 158s 638ms/step - loss: 0.7055 - accuracy: 0.7441 - val_loss: 0.9247 - val_accuracy: 0.6571\n",
    "Epoch 23/50\n",
    "248/248 [==============================] - 226s 900ms/step - loss: 0.6734 - accuracy: 0.7484 - val_loss: 0.9695 - val_accuracy: 0.6505\n",
    "Epoch 24/50\n",
    "248/248 [==============================] - 120s 472ms/step - loss: 0.6795 - accuracy: 0.7561 - val_loss: 0.9473 - val_accuracy: 0.6490\n",
    "Epoch 25/50\n",
    "248/248 [==============================] - 70s 277ms/step - loss: 0.6619 - accuracy: 0.7586 - val_loss: 1.2839 - val_accuracy: 0.5722\n",
    "Epoch 26/50\n",
    "248/248 [==============================] - 69s 271ms/step - loss: 0.6461 - accuracy: 0.7688 - val_loss: 0.9957 - val_accuracy: 0.6424\n",
    "Epoch 27/50\n",
    "248/248 [==============================] - 71s 279ms/step - loss: 0.6483 - accuracy: 0.7585 - val_loss: 0.9987 - val_accuracy: 0.6182\n",
    "Epoch 28/50\n",
    "248/248 [==============================] - 69s 271ms/step - loss: 0.6224 - accuracy: 0.7761 - val_loss: 1.1136 - val_accuracy: 0.6005\n",
    "Epoch 29/50\n",
    "248/248 [==============================] - 67s 265ms/step - loss: 0.6004 - accuracy: 0.7845 - val_loss: 1.3182 - val_accuracy: 0.5424\n",
    "Epoch 30/50\n",
    "248/248 [==============================] - 67s 267ms/step - loss: 0.5958 - accuracy: 0.7773 - val_loss: 0.8463 - val_accuracy: 0.6965\n",
    "Epoch 31/50\n",
    "248/248 [==============================] - 68s 270ms/step - loss: 0.5796 - accuracy: 0.7884 - val_loss: 1.1723 - val_accuracy: 0.6313\n",
    "Epoch 32/50\n",
    "248/248 [==============================] - 69s 272ms/step - loss: 0.5667 - accuracy: 0.7948 - val_loss: 1.5287 - val_accuracy: 0.5444\n",
    "Epoch 33/50\n",
    "248/248 [==============================] - 69s 271ms/step - loss: 0.5527 - accuracy: 0.7986 - val_loss: 2.2422 - val_accuracy: 0.4258\n",
    "Epoch 34/50\n",
    "248/248 [==============================] - 70s 274ms/step - loss: 0.5402 - accuracy: 0.8013 - val_loss: 1.1519 - val_accuracy: 0.6035\n",
    "Epoch 35/50\n",
    "248/248 [==============================] - 69s 272ms/step - loss: 0.5404 - accuracy: 0.8038 - val_loss: 1.2811 - val_accuracy: 0.5707\n",
    "Epoch 36/50\n",
    "248/248 [==============================] - 74s 292ms/step - loss: 0.5315 - accuracy: 0.8093 - val_loss: 0.9980 - val_accuracy: 0.6384\n",
    "Epoch 37/50\n",
    "248/248 [==============================] - 71s 280ms/step - loss: 0.5168 - accuracy: 0.8129 - val_loss: 1.0805 - val_accuracy: 0.6646\n",
    "Epoch 38/50\n",
    "248/248 [==============================] - 72s 284ms/step - loss: 0.4945 - accuracy: 0.8196 - val_loss: 0.9460 - val_accuracy: 0.6960\n",
    "Epoch 39/50\n",
    "248/248 [==============================] - 73s 291ms/step - loss: 0.4874 - accuracy: 0.8240 - val_loss: 1.0394 - val_accuracy: 0.6571\n",
    "Epoch 40/50\n",
    "248/248 [==============================] - 70s 279ms/step - loss: 0.4777 - accuracy: 0.8304 - val_loss: 0.8866 - val_accuracy: 0.7010\n",
    "Epoch 41/50\n",
    "248/248 [==============================] - 74s 293ms/step - loss: 0.4660 - accuracy: 0.8336 - val_loss: 0.9157 - val_accuracy: 0.7313\n",
    "Epoch 42/50\n",
    "248/248 [==============================] - 73s 290ms/step - loss: 0.4612 - accuracy: 0.8337 - val_loss: 0.9323 - val_accuracy: 0.6919\n",
    "Epoch 43/50\n",
    "248/248 [==============================] - 68s 266ms/step - loss: 0.4624 - accuracy: 0.8328 - val_loss: 1.1074 - val_accuracy: 0.6465\n",
    "Epoch 44/50\n",
    "248/248 [==============================] - 68s 270ms/step - loss: 0.4525 - accuracy: 0.8352 - val_loss: 0.9140 - val_accuracy: 0.6783\n",
    "Epoch 45/50\n",
    "248/248 [==============================] - 67s 265ms/step - loss: 0.4222 - accuracy: 0.8475 - val_loss: 1.0781 - val_accuracy: 0.7030\n",
    "Epoch 46/50\n",
    "248/248 [==============================] - 67s 265ms/step - loss: 0.4259 - accuracy: 0.8443 - val_loss: 1.4111 - val_accuracy: 0.6081\n",
    "Epoch 47/50\n",
    "248/248 [==============================] - 67s 267ms/step - loss: 0.4195 - accuracy: 0.8501 - val_loss: 0.9660 - val_accuracy: 0.6955\n",
    "Epoch 48/50\n",
    "248/248 [==============================] - 67s 264ms/step - loss: 0.4069 - accuracy: 0.8533 - val_loss: 1.0502 - val_accuracy: 0.6828\n",
    "Epoch 49/50\n",
    "248/248 [==============================] - 69s 273ms/step - loss: 0.4001 - accuracy: 0.8585 - val_loss: 0.8679 - val_accuracy: 0.7359\n",
    "Epoch 50/50\n",
    "248/248 [==============================] - 69s 271ms/step - loss: 0.3906 - accuracy: 0.8585 - val_loss: 0.9986 - val_accuracy: 0.6939\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "248/248 [==============================] - 72s 289ms/step - loss: 1.2773 - accuracy: 0.4712 - val_loss: 1.3034 - val_accuracy: 0.4328\n",
      "Epoch 2/25\n",
      "248/248 [==============================] - 75s 301ms/step - loss: 1.2320 - accuracy: 0.4870 - val_loss: 1.2567 - val_accuracy: 0.4616\n",
      "Epoch 3/25\n",
      "248/248 [==============================] - 74s 299ms/step - loss: 1.2040 - accuracy: 0.4976 - val_loss: 1.2643 - val_accuracy: 0.4742\n",
      "Epoch 4/25\n",
      "248/248 [==============================] - 71s 285ms/step - loss: 1.1740 - accuracy: 0.5124 - val_loss: 1.2547 - val_accuracy: 0.4828\n",
      "Epoch 5/25\n",
      "248/248 [==============================] - 68s 273ms/step - loss: 1.1471 - accuracy: 0.5201 - val_loss: 1.2098 - val_accuracy: 0.4843\n",
      "Epoch 6/25\n",
      "248/248 [==============================] - 69s 277ms/step - loss: 1.1275 - accuracy: 0.5391 - val_loss: 1.2341 - val_accuracy: 0.4874\n",
      "Epoch 7/25\n",
      "248/248 [==============================] - 69s 277ms/step - loss: 1.1129 - accuracy: 0.5418 - val_loss: 1.1816 - val_accuracy: 0.4859\n",
      "Epoch 8/25\n",
      "248/248 [==============================] - 71s 285ms/step - loss: 1.0977 - accuracy: 0.5491 - val_loss: 1.1706 - val_accuracy: 0.5010\n",
      "Epoch 9/25\n",
      "248/248 [==============================] - 74s 298ms/step - loss: 1.0855 - accuracy: 0.5582 - val_loss: 1.1858 - val_accuracy: 0.4995\n",
      "Epoch 10/25\n",
      "248/248 [==============================] - 82s 330ms/step - loss: 1.0719 - accuracy: 0.5601 - val_loss: 1.1488 - val_accuracy: 0.5232\n",
      "Epoch 11/25\n",
      "248/248 [==============================] - 77s 311ms/step - loss: 1.0565 - accuracy: 0.5673 - val_loss: 1.1564 - val_accuracy: 0.5081\n",
      "Epoch 12/25\n",
      "248/248 [==============================] - 83s 334ms/step - loss: 1.0475 - accuracy: 0.5720 - val_loss: 1.1380 - val_accuracy: 0.5263\n",
      "Epoch 13/25\n",
      "248/248 [==============================] - 78s 315ms/step - loss: 1.0212 - accuracy: 0.5830 - val_loss: 1.1277 - val_accuracy: 0.5409\n",
      "Epoch 14/25\n",
      "248/248 [==============================] - 77s 311ms/step - loss: 1.0180 - accuracy: 0.5896 - val_loss: 1.1343 - val_accuracy: 0.5303\n",
      "Epoch 15/25\n",
      "248/248 [==============================] - 75s 301ms/step - loss: 1.0092 - accuracy: 0.5909 - val_loss: 1.1110 - val_accuracy: 0.5495\n",
      "Epoch 16/25\n",
      "248/248 [==============================] - 74s 300ms/step - loss: 0.9956 - accuracy: 0.6027 - val_loss: 1.0981 - val_accuracy: 0.5414\n",
      "Epoch 17/25\n",
      "248/248 [==============================] - 76s 305ms/step - loss: 0.9845 - accuracy: 0.6039 - val_loss: 1.1212 - val_accuracy: 0.5404\n",
      "Epoch 18/25\n",
      "248/248 [==============================] - 74s 299ms/step - loss: 0.9641 - accuracy: 0.6081 - val_loss: 1.1128 - val_accuracy: 0.5394\n",
      "Epoch 19/25\n",
      "248/248 [==============================] - 77s 310ms/step - loss: 0.9643 - accuracy: 0.6112 - val_loss: 1.1221 - val_accuracy: 0.5369\n",
      "Epoch 20/25\n",
      "248/248 [==============================] - 73s 292ms/step - loss: 0.9604 - accuracy: 0.6153 - val_loss: 1.0986 - val_accuracy: 0.5419\n",
      "Epoch 21/25\n",
      "248/248 [==============================] - 76s 308ms/step - loss: 0.9489 - accuracy: 0.6184 - val_loss: 1.1061 - val_accuracy: 0.5561\n",
      "Epoch 22/25\n",
      "248/248 [==============================] - 78s 316ms/step - loss: 0.9239 - accuracy: 0.6245 - val_loss: 1.1285 - val_accuracy: 0.5490\n",
      "Epoch 23/25\n",
      "248/248 [==============================] - 77s 312ms/step - loss: 0.9365 - accuracy: 0.6208 - val_loss: 1.0964 - val_accuracy: 0.5561\n",
      "Epoch 24/25\n",
      "248/248 [==============================] - 73s 292ms/step - loss: 0.9049 - accuracy: 0.6326 - val_loss: 1.1084 - val_accuracy: 0.5495\n",
      "Epoch 25/25\n",
      "248/248 [==============================] - 75s 302ms/step - loss: 0.9130 - accuracy: 0.6385 - val_loss: 1.0783 - val_accuracy: 0.5742\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Define the number of layers to freeze from the base model\n",
    "# Freeze layers except for the last few\n",
    "freeze_layers = 10  # Number of layers to freeze\n",
    "for layer in model.layers[:-freeze_layers]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
