{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7920 images belonging to 5 classes.\n",
      "Found 1980 images belonging to 5 classes.\n",
      "Found 100 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Directories\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Data generator for training data\n",
    "\n",
    "# Data generator for training data with validation split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=40,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)  # 20% validation split\n",
    "\n",
    "# Separate generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')  # Specify 'training' subset\n",
    "\n",
    "# Separate generator for validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')  # Specify 'validation' subset\n",
    "\n",
    "\n",
    "\n",
    "# Data generator for test data\n",
    "test_files = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))]\n",
    "\n",
    "# Create a DataFrame with the filenames\n",
    "test_df = pd.DataFrame({\"Filename\": test_files})\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='Filename',\n",
    "    y_col=None,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####PRETRAINED MODEL\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, stride=1, use_projection=False):\n",
    "    shortcut = x\n",
    "    if use_projection:\n",
    "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=stride, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # First convolutional layer\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Add shortcut to the output\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet50(input_shape=(227, 227, 3), num_classes=5):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolutional layer\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = residual_block(x, filters=64, use_projection=True)\n",
    "    x = residual_block(x, filters=64)\n",
    "    x = residual_block(x, filters=64)\n",
    "\n",
    "    x = residual_block(x, filters=128, stride=2, use_projection=True)\n",
    "    x = residual_block(x, filters=128)\n",
    "    x = residual_block(x, filters=128)\n",
    "    x = residual_block(x, filters=128)\n",
    "\n",
    "    x = residual_block(x, filters=256, stride=2, use_projection=True)\n",
    "    x = residual_block(x, filters=256)\n",
    "    x = residual_block(x, filters=256)\n",
    "    x = residual_block(x, filters=256)\n",
    "    x = residual_block(x, filters=256)\n",
    "    x = residual_block(x, filters=256)\n",
    "\n",
    "    x = residual_block(x, filters=512, stride=2, use_projection=True)\n",
    "    x = residual_block(x, filters=512)\n",
    "    x = residual_block(x, filters=512)\n",
    "\n",
    "    # Final layers\n",
    "    x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Create ResNet50 model\n",
    "resnet50_model = ResNet50()\n",
    "\n",
    "# Display the model summary\n",
    "resnet50_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"model\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_1 (InputLayer)           [(None, 227, 227, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d (Conv2D)                (None, 114, 114, 64  9472        ['input_1[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " batch_normalization (BatchNorm  (None, 114, 114, 64  256        ['conv2d[0][0]']                 \n",
    " alization)                     )                                                                 \n",
    "                                                                                                  \n",
    " activation (Activation)        (None, 114, 114, 64  0           ['batch_normalization[0][0]']    \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d (MaxPooling2D)   (None, 57, 57, 64)   0           ['activation[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_2 (Conv2D)              (None, 57, 57, 64)   36928       ['max_pooling2d[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_2 (BatchNo  (None, 57, 57, 64)  256         ['conv2d_2[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " activation_1 (Activation)      (None, 57, 57, 64)   0           ['batch_normalization_2[0][0]']  \n",
    "                                                                                                  \n",
    " conv2d_3 (Conv2D)              (None, 57, 57, 64)   36928       ['activation_1[0][0]']           \n",
    "                                                                                                  \n",
    " conv2d_1 (Conv2D)              (None, 57, 57, 64)   4160        ['max_pooling2d[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_3 (BatchNo  (None, 57, 57, 64)  256         ['conv2d_3[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " batch_normalization_1 (BatchNo  (None, 57, 57, 64)  256         ['conv2d_1[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " add (Add)                      (None, 57, 57, 64)   0           ['batch_normalization_3[0][0]',  \n",
    "                                                                  'batch_normalization_1[0][0]']  \n",
    "                                                                                                  \n",
    " activation_2 (Activation)      (None, 57, 57, 64)   0           ['add[0][0]']                    \n",
    "                                                                                                  \n",
    " conv2d_4 (Conv2D)              (None, 57, 57, 64)   36928       ['activation_2[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_4 (BatchNo  (None, 57, 57, 64)  256         ['conv2d_4[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " activation_3 (Activation)      (None, 57, 57, 64)   0           ['batch_normalization_4[0][0]']  \n",
    "                                                                                                  \n",
    " conv2d_5 (Conv2D)              (None, 57, 57, 64)   36928       ['activation_3[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_5 (BatchNo  (None, 57, 57, 64)  256         ['conv2d_5[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " add_1 (Add)                    (None, 57, 57, 64)   0           ['batch_normalization_5[0][0]',  \n",
    "                                                                  'activation_2[0][0]']           \n",
    "                                                                                                  \n",
    " activation_4 (Activation)      (None, 57, 57, 64)   0           ['add_1[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_6 (Conv2D)              (None, 57, 57, 64)   36928       ['activation_4[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_6 (BatchNo  (None, 57, 57, 64)  256         ['conv2d_6[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " activation_5 (Activation)      (None, 57, 57, 64)   0           ['batch_normalization_6[0][0]']  \n",
    "                                                                                                  \n",
    " conv2d_7 (Conv2D)              (None, 57, 57, 64)   36928       ['activation_5[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_7 (BatchNo  (None, 57, 57, 64)  256         ['conv2d_7[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " add_2 (Add)                    (None, 57, 57, 64)   0           ['batch_normalization_7[0][0]',  \n",
    "                                                                  'activation_4[0][0]']           \n",
    "                                                                                                  \n",
    " activation_6 (Activation)      (None, 57, 57, 64)   0           ['add_2[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_9 (Conv2D)              (None, 29, 29, 128)  73856       ['activation_6[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_9 (BatchNo  (None, 29, 29, 128)  512        ['conv2d_9[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " activation_7 (Activation)      (None, 29, 29, 128)  0           ['batch_normalization_9[0][0]']  \n",
    "                                                                                                  \n",
    " conv2d_10 (Conv2D)             (None, 29, 29, 128)  147584      ['activation_7[0][0]']           \n",
    "                                                                                                  \n",
    " conv2d_8 (Conv2D)              (None, 29, 29, 128)  8320        ['activation_6[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_10 (BatchN  (None, 29, 29, 128)  512        ['conv2d_10[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " batch_normalization_8 (BatchNo  (None, 29, 29, 128)  512        ['conv2d_8[0][0]']               \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " add_3 (Add)                    (None, 29, 29, 128)  0           ['batch_normalization_10[0][0]', \n",
    "                                                                  'batch_normalization_8[0][0]']  \n",
    "                                                                                                  \n",
    " activation_8 (Activation)      (None, 29, 29, 128)  0           ['add_3[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_11 (Conv2D)             (None, 29, 29, 128)  147584      ['activation_8[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_11 (BatchN  (None, 29, 29, 128)  512        ['conv2d_11[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_9 (Activation)      (None, 29, 29, 128)  0           ['batch_normalization_11[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_12 (Conv2D)             (None, 29, 29, 128)  147584      ['activation_9[0][0]']           \n",
    "                                                                                                  \n",
    " batch_normalization_12 (BatchN  (None, 29, 29, 128)  512        ['conv2d_12[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_4 (Add)                    (None, 29, 29, 128)  0           ['batch_normalization_12[0][0]', \n",
    "                                                                  'activation_8[0][0]']           \n",
    "                                                                                                  \n",
    " activation_10 (Activation)     (None, 29, 29, 128)  0           ['add_4[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_13 (Conv2D)             (None, 29, 29, 128)  147584      ['activation_10[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_13 (BatchN  (None, 29, 29, 128)  512        ['conv2d_13[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_11 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_13[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_14 (Conv2D)             (None, 29, 29, 128)  147584      ['activation_11[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_14 (BatchN  (None, 29, 29, 128)  512        ['conv2d_14[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_5 (Add)                    (None, 29, 29, 128)  0           ['batch_normalization_14[0][0]', \n",
    "                                                                  'activation_10[0][0]']          \n",
    "                                                                                                  \n",
    " activation_12 (Activation)     (None, 29, 29, 128)  0           ['add_5[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_15 (Conv2D)             (None, 29, 29, 128)  147584      ['activation_12[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_15 (BatchN  (None, 29, 29, 128)  512        ['conv2d_15[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_13 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_15[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_16 (Conv2D)             (None, 29, 29, 128)  147584      ['activation_13[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_16 (BatchN  (None, 29, 29, 128)  512        ['conv2d_16[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_6 (Add)                    (None, 29, 29, 128)  0           ['batch_normalization_16[0][0]', \n",
    "                                                                  'activation_12[0][0]']          \n",
    "                                                                                                  \n",
    " activation_14 (Activation)     (None, 29, 29, 128)  0           ['add_6[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_18 (Conv2D)             (None, 15, 15, 256)  295168      ['activation_14[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_18 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_18[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_15 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_18[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_19 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_15[0][0]']          \n",
    "                                                                                                  \n",
    " conv2d_17 (Conv2D)             (None, 15, 15, 256)  33024       ['activation_14[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_19 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_19[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " batch_normalization_17 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_17[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_7 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_19[0][0]', \n",
    "                                                                  'batch_normalization_17[0][0]'] \n",
    "                                                                                                  \n",
    " activation_16 (Activation)     (None, 15, 15, 256)  0           ['add_7[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_20 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_16[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_20 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_20[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_17 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_20[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_21 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_17[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_21 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_21[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_8 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_21[0][0]', \n",
    "                                                                  'activation_16[0][0]']          \n",
    "                                                                                                  \n",
    " activation_18 (Activation)     (None, 15, 15, 256)  0           ['add_8[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_22 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_18[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_22 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_22[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_19 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_22[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_23 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_19[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_23 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_23[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_9 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_23[0][0]', \n",
    "                                                                  'activation_18[0][0]']          \n",
    "                                                                                                  \n",
    " activation_20 (Activation)     (None, 15, 15, 256)  0           ['add_9[0][0]']                  \n",
    "                                                                                                  \n",
    " conv2d_24 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_20[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_24 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_24[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_21 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_24[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_25 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_21[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_25 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_25[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_10 (Add)                   (None, 15, 15, 256)  0           ['batch_normalization_25[0][0]', \n",
    "                                                                  'activation_20[0][0]']          \n",
    "                                                                                                  \n",
    " activation_22 (Activation)     (None, 15, 15, 256)  0           ['add_10[0][0]']                 \n",
    "                                                                                                  \n",
    " conv2d_26 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_22[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_26 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_26[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_23 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_26[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_27 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_23[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_27 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_27[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_11 (Add)                   (None, 15, 15, 256)  0           ['batch_normalization_27[0][0]', \n",
    "                                                                  'activation_22[0][0]']          \n",
    "                                                                                                  \n",
    " activation_24 (Activation)     (None, 15, 15, 256)  0           ['add_11[0][0]']                 \n",
    "                                                                                                  \n",
    " conv2d_28 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_24[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_28 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_28[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_25 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_28[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_29 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_25[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_29 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_29[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_12 (Add)                   (None, 15, 15, 256)  0           ['batch_normalization_29[0][0]', \n",
    "                                                                  'activation_24[0][0]']          \n",
    "                                                                                                  \n",
    " activation_26 (Activation)     (None, 15, 15, 256)  0           ['add_12[0][0]']                 \n",
    "                                                                                                  \n",
    " conv2d_31 (Conv2D)             (None, 8, 8, 512)    1180160     ['activation_26[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_31 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_31[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_27 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_31[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_32 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_27[0][0]']          \n",
    "                                                                                                  \n",
    " conv2d_30 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_26[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_32 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_32[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " batch_normalization_30 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_30[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_13 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_32[0][0]', \n",
    "                                                                  'batch_normalization_30[0][0]'] \n",
    "                                                                                                  \n",
    " activation_28 (Activation)     (None, 8, 8, 512)    0           ['add_13[0][0]']                 \n",
    "                                                                                                  \n",
    " conv2d_33 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_28[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_33 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_33[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_29 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_33[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_34 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_29[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_34 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_34[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_14 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_34[0][0]', \n",
    "                                                                  'activation_28[0][0]']          \n",
    "                                                                                                  \n",
    " activation_30 (Activation)     (None, 8, 8, 512)    0           ['add_14[0][0]']                 \n",
    "                                                                                                  \n",
    " conv2d_35 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_30[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_35 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_35[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " activation_31 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_35[0][0]'] \n",
    "                                                                                                  \n",
    " conv2d_36 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_31[0][0]']          \n",
    "                                                                                                  \n",
    " batch_normalization_36 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_36[0][0]']              \n",
    " ormalization)                                                                                    \n",
    "                                                                                                  \n",
    " add_15 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_36[0][0]', \n",
    "                                                                  'activation_30[0][0]']          \n",
    "                                                                                                  \n",
    " activation_32 (Activation)     (None, 8, 8, 512)    0           ['add_15[0][0]']                 \n",
    "                                                                                                  \n",
    " average_pooling2d (AveragePool  (None, 1, 1, 512)   0           ['activation_32[0][0]']          \n",
    " ing2D)                                                                                           \n",
    "                                                                                                  \n",
    " flatten (Flatten)              (None, 512)          0           ['average_pooling2d[0][0]']      \n",
    "                                                                                                  \n",
    " dense (Dense)                  (None, 5)            2565        ['flatten[0][0]']                \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 21,317,189\n",
    "Trainable params: 21,300,037\n",
    "Non-trainable params: 17,152\n",
    "__________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet50_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "               \n",
    "resnet50_model.fit(train_generator, \n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=40,\n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=len(validation_generator),\n",
    "   ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####output\n",
    "Epoch 1/40\n",
    "248/248 [==============================] - 95s 342ms/step - loss: 1.3395 - accuracy: 0.4865 - val_loss: 2.7333 - val_accuracy: 0.2061\n",
    "Epoch 2/40\n",
    "248/248 [==============================] - 80s 324ms/step - loss: 1.0810 - accuracy: 0.5756 - val_loss: 1.6324 - val_accuracy: 0.3833\n",
    "Epoch 3/40\n",
    "248/248 [==============================] - 77s 311ms/step - loss: 1.0123 - accuracy: 0.6034 - val_loss: 1.3618 - val_accuracy: 0.4611\n",
    "Epoch 4/40\n",
    "248/248 [==============================] - 80s 320ms/step - loss: 0.9654 - accuracy: 0.6221 - val_loss: 1.5169 - val_accuracy: 0.4025\n",
    "Epoch 5/40\n",
    "248/248 [==============================] - 79s 319ms/step - loss: 0.9078 - accuracy: 0.6484 - val_loss: 1.2966 - val_accuracy: 0.4652\n",
    "Epoch 6/40\n",
    "248/248 [==============================] - 78s 314ms/step - loss: 0.9135 - accuracy: 0.6441 - val_loss: 1.4587 - val_accuracy: 0.4505\n",
    "Epoch 7/40\n",
    "248/248 [==============================] - 71s 285ms/step - loss: 0.8455 - accuracy: 0.6734 - val_loss: 1.1951 - val_accuracy: 0.5333\n",
    "Epoch 8/40\n",
    "248/248 [==============================] - 81s 326ms/step - loss: 0.8332 - accuracy: 0.6843 - val_loss: 1.1367 - val_accuracy: 0.5591\n",
    "Epoch 9/40\n",
    "248/248 [==============================] - 73s 295ms/step - loss: 0.8010 - accuracy: 0.6994 - val_loss: 1.2691 - val_accuracy: 0.5364\n",
    "Epoch 10/40\n",
    "248/248 [==============================] - 73s 295ms/step - loss: 0.7842 - accuracy: 0.7081 - val_loss: 1.2890 - val_accuracy: 0.5045\n",
    "Epoch 11/40\n",
    "248/248 [==============================] - 71s 287ms/step - loss: 0.8036 - accuracy: 0.6934 - val_loss: 0.9537 - val_accuracy: 0.6571\n",
    "Epoch 12/40\n",
    "248/248 [==============================] - 74s 298ms/step - loss: 0.7489 - accuracy: 0.7178 - val_loss: 0.9610 - val_accuracy: 0.6222\n",
    "Epoch 13/40\n",
    "248/248 [==============================] - 71s 284ms/step - loss: 0.7406 - accuracy: 0.7232 - val_loss: 1.8443 - val_accuracy: 0.4990\n",
    "Epoch 14/40\n",
    "248/248 [==============================] - 73s 293ms/step - loss: 0.7087 - accuracy: 0.7348 - val_loss: 1.1407 - val_accuracy: 0.6035\n",
    "Epoch 15/40\n",
    "248/248 [==============================] - 72s 291ms/step - loss: 0.6940 - accuracy: 0.7399 - val_loss: 1.6511 - val_accuracy: 0.4298\n",
    "Epoch 16/40\n",
    "248/248 [==============================] - 74s 299ms/step - loss: 0.6822 - accuracy: 0.7423 - val_loss: 0.9037 - val_accuracy: 0.6591\n",
    "Epoch 17/40\n",
    "248/248 [==============================] - 71s 285ms/step - loss: 0.6816 - accuracy: 0.7446 - val_loss: 1.8166 - val_accuracy: 0.4909\n",
    "Epoch 18/40\n",
    "248/248 [==============================] - 74s 296ms/step - loss: 0.6692 - accuracy: 0.7491 - val_loss: 0.8350 - val_accuracy: 0.7015\n",
    "Epoch 19/40\n",
    "248/248 [==============================] - 71s 287ms/step - loss: 0.6396 - accuracy: 0.7605 - val_loss: 1.0367 - val_accuracy: 0.6051\n",
    "Epoch 20/40\n",
    "248/248 [==============================] - 77s 309ms/step - loss: 0.6412 - accuracy: 0.7611 - val_loss: 1.1777 - val_accuracy: 0.6263\n",
    "Epoch 21/40\n",
    "248/248 [==============================] - 72s 288ms/step - loss: 0.6482 - accuracy: 0.7598 - val_loss: 10.3072 - val_accuracy: 0.5268\n",
    "Epoch 22/40\n",
    "248/248 [==============================] - 74s 298ms/step - loss: 0.6120 - accuracy: 0.7679 - val_loss: 1.8083 - val_accuracy: 0.6247\n",
    "Epoch 23/40\n",
    "248/248 [==============================] - 72s 291ms/step - loss: 0.6006 - accuracy: 0.7754 - val_loss: 1.1416 - val_accuracy: 0.6237\n",
    "Epoch 24/40\n",
    "248/248 [==============================] - 79s 317ms/step - loss: 0.5943 - accuracy: 0.7785 - val_loss: 2.1000 - val_accuracy: 0.4323\n",
    "Epoch 25/40\n",
    "248/248 [==============================] - 71s 284ms/step - loss: 0.5797 - accuracy: 0.7860 - val_loss: 0.9031 - val_accuracy: 0.6727\n",
    "Epoch 26/40\n",
    "248/248 [==============================] - 73s 295ms/step - loss: 0.5711 - accuracy: 0.7843 - val_loss: 1.1866 - val_accuracy: 0.5803\n",
    "Epoch 27/40\n",
    "248/248 [==============================] - 72s 291ms/step - loss: 0.5482 - accuracy: 0.7994 - val_loss: 1.1587 - val_accuracy: 0.6182\n",
    "Epoch 28/40\n",
    "248/248 [==============================] - 74s 296ms/step - loss: 0.5567 - accuracy: 0.8001 - val_loss: 1.0715 - val_accuracy: 0.6141\n",
    "Epoch 29/40\n",
    "248/248 [==============================] - 71s 286ms/step - loss: 0.5336 - accuracy: 0.8033 - val_loss: 0.9237 - val_accuracy: 0.6515\n",
    "Epoch 30/40\n",
    "248/248 [==============================] - 74s 298ms/step - loss: 0.5157 - accuracy: 0.8128 - val_loss: 0.7923 - val_accuracy: 0.7187\n",
    "Epoch 31/40\n",
    "248/248 [==============================] - 78s 312ms/step - loss: 0.5095 - accuracy: 0.8135 - val_loss: 1.2877 - val_accuracy: 0.5566\n",
    "Epoch 32/40\n",
    "248/248 [==============================] - 78s 314ms/step - loss: 0.4935 - accuracy: 0.8203 - val_loss: 1.0260 - val_accuracy: 0.6404\n",
    "Epoch 33/40\n",
    "248/248 [==============================] - 70s 283ms/step - loss: 0.4944 - accuracy: 0.8187 - val_loss: 1.0167 - val_accuracy: 0.6485\n",
    "Epoch 34/40\n",
    "248/248 [==============================] - 72s 288ms/step - loss: 0.4812 - accuracy: 0.8277 - val_loss: 1.0302 - val_accuracy: 0.6399\n",
    "Epoch 35/40\n",
    "248/248 [==============================] - 71s 287ms/step - loss: 0.4611 - accuracy: 0.8311 - val_loss: 0.9923 - val_accuracy: 0.6621\n",
    "Epoch 36/40\n",
    "248/248 [==============================] - 73s 292ms/step - loss: 0.4513 - accuracy: 0.8298 - val_loss: 1.2575 - val_accuracy: 0.6035\n",
    "Epoch 37/40\n",
    "248/248 [==============================] - 69s 279ms/step - loss: 0.4471 - accuracy: 0.8369 - val_loss: 0.9494 - val_accuracy: 0.6682\n",
    "Epoch 38/40\n",
    "248/248 [==============================] - 77s 309ms/step - loss: 0.4359 - accuracy: 0.8405 - val_loss: 0.8327 - val_accuracy: 0.7545\n",
    "Epoch 39/40\n",
    "248/248 [==============================] - 70s 282ms/step - loss: 0.4237 - accuracy: 0.8489 - val_loss: 1.1590 - val_accuracy: 0.6389\n",
    "Epoch 40/40\n",
    "248/248 [==============================] - 73s 294ms/step - loss: 0.4163 - accuracy: 0.8485 - val_loss: 0.8049 - val_accuracy: 0.7152\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 64  9472        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 112, 112, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 112, 112, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 56, 56, 64)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 56, 56, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 56, 56, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 56, 56, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 56, 56, 64)   0           ['dropout[0][0]',                \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 56, 56, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   36928       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   36928       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 56, 56, 64)   0           ['dropout_1[0][0]',              \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 28, 28, 128)  73856       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 28, 28, 128)  147584      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 28, 28, 128)  8320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 28, 28, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 28, 28, 128)  0           ['dropout_2[0][0]',              \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 28, 28, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 28, 28, 128)  147584      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 28, 28, 128)  512        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 28, 28, 128)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 28, 28, 128)  0           ['dropout_3[0][0]',              \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 28, 28, 128)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 14, 14, 256)  295168      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 14, 14, 256)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 14, 14, 256)  33024       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 14, 14, 256)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 14, 14, 256)  0           ['dropout_4[0][0]',              \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 14, 14, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 14, 14, 256)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 14, 14, 256)  0           ['dropout_5[0][0]',              \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 14, 14, 256)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 2, 2, 256)   0           ['activation_12[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5)            5125        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,799,045\n",
      "Trainable params: 2,794,437\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def residual_block(x, filters, stride=1, use_projection=False):\n",
    "    shortcut = x\n",
    "    if use_projection:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=(1, 1), strides=stride, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    # First convolutional layer\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Add dropout for regularization\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Add shortcut to the output\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet50_modified(input_shape=(224, 224, 3), num_classes=5):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolutional layer\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Reduced number of residual blocks for brevity\n",
    "    x = residual_block(x, filters=64, use_projection=True)\n",
    "    x = residual_block(x, filters=64)\n",
    "    x = residual_block(x, filters=128, stride=2, use_projection=True)\n",
    "    x = residual_block(x, filters=128)\n",
    "\n",
    "    # Fewer residual blocks for illustration purposes\n",
    "    x = residual_block(x, filters=256, stride=2, use_projection=True)\n",
    "    x = residual_block(x, filters=256)\n",
    "\n",
    "    x = layers.AveragePooling2D(pool_size=(7, 7))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Create the modified ResNet50 model\n",
    "modified_resnet50_model = ResNet50_modified()\n",
    "\n",
    "# Display the model summary\n",
    "modified_resnet50_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "248/248 [==============================] - 87s 315ms/step - loss: 1.2526 - accuracy: 0.5020 - val_loss: 1.7502 - val_accuracy: 0.3470\n",
      "Epoch 2/40\n",
      "248/248 [==============================] - 77s 305ms/step - loss: 1.0527 - accuracy: 0.5784 - val_loss: 1.4090 - val_accuracy: 0.4455\n",
      "Epoch 3/40\n",
      "248/248 [==============================] - 72s 287ms/step - loss: 0.9792 - accuracy: 0.6187 - val_loss: 1.9027 - val_accuracy: 0.4146\n",
      "Epoch 4/40\n",
      "248/248 [==============================] - 70s 276ms/step - loss: 0.9164 - accuracy: 0.6439 - val_loss: 1.4428 - val_accuracy: 0.5091\n",
      "Epoch 5/40\n",
      "248/248 [==============================] - 73s 289ms/step - loss: 0.8915 - accuracy: 0.6510 - val_loss: 1.3247 - val_accuracy: 0.4833\n",
      "Epoch 6/40\n",
      "248/248 [==============================] - 73s 288ms/step - loss: 0.8607 - accuracy: 0.6736 - val_loss: 1.6130 - val_accuracy: 0.5242\n",
      "Epoch 7/40\n",
      "248/248 [==============================] - 72s 285ms/step - loss: 0.8112 - accuracy: 0.6912 - val_loss: 1.4683 - val_accuracy: 0.4697\n",
      "Epoch 8/40\n",
      "248/248 [==============================] - 70s 279ms/step - loss: 0.8132 - accuracy: 0.6923 - val_loss: 2.2308 - val_accuracy: 0.5414\n",
      "Epoch 9/40\n",
      "248/248 [==============================] - 73s 291ms/step - loss: 0.7757 - accuracy: 0.7085 - val_loss: 1.0999 - val_accuracy: 0.5854\n",
      "Epoch 10/40\n",
      "248/248 [==============================] - 69s 273ms/step - loss: 0.7786 - accuracy: 0.7034 - val_loss: 1.8217 - val_accuracy: 0.4379\n",
      "Epoch 11/40\n",
      "248/248 [==============================] - 76s 304ms/step - loss: 0.7429 - accuracy: 0.7173 - val_loss: 1.0205 - val_accuracy: 0.5949\n",
      "Epoch 12/40\n",
      "248/248 [==============================] - 72s 285ms/step - loss: 0.7312 - accuracy: 0.7211 - val_loss: 0.9814 - val_accuracy: 0.6581\n",
      "Epoch 13/40\n",
      "248/248 [==============================] - 73s 292ms/step - loss: 0.7199 - accuracy: 0.7302 - val_loss: 0.9266 - val_accuracy: 0.6591\n",
      "Epoch 14/40\n",
      "248/248 [==============================] - 68s 270ms/step - loss: 0.7082 - accuracy: 0.7366 - val_loss: 0.9710 - val_accuracy: 0.6571\n",
      "Epoch 15/40\n",
      "248/248 [==============================] - 70s 276ms/step - loss: 0.6904 - accuracy: 0.7378 - val_loss: 0.9258 - val_accuracy: 0.6207\n",
      "Epoch 16/40\n",
      "248/248 [==============================] - 70s 278ms/step - loss: 0.6762 - accuracy: 0.7476 - val_loss: 1.0936 - val_accuracy: 0.5545\n",
      "Epoch 17/40\n",
      "248/248 [==============================] - 81s 321ms/step - loss: 0.6568 - accuracy: 0.7552 - val_loss: 1.1306 - val_accuracy: 0.5798\n",
      "Epoch 18/40\n",
      "248/248 [==============================] - 82s 328ms/step - loss: 0.6607 - accuracy: 0.7551 - val_loss: 0.9584 - val_accuracy: 0.6672\n",
      "Epoch 19/40\n",
      "248/248 [==============================] - 75s 300ms/step - loss: 0.6392 - accuracy: 0.7610 - val_loss: 0.9978 - val_accuracy: 0.6379\n",
      "Epoch 20/40\n",
      "248/248 [==============================] - 78s 310ms/step - loss: 0.6200 - accuracy: 0.7689 - val_loss: 1.0209 - val_accuracy: 0.6000\n",
      "Epoch 21/40\n",
      "248/248 [==============================] - 75s 299ms/step - loss: 0.6265 - accuracy: 0.7619 - val_loss: 0.9380 - val_accuracy: 0.6576\n",
      "Epoch 22/40\n",
      "248/248 [==============================] - 76s 303ms/step - loss: 0.6045 - accuracy: 0.7788 - val_loss: 0.8574 - val_accuracy: 0.6768\n",
      "Epoch 23/40\n",
      "248/248 [==============================] - 77s 305ms/step - loss: 0.6107 - accuracy: 0.7694 - val_loss: 0.9758 - val_accuracy: 0.6626\n",
      "Epoch 24/40\n",
      "248/248 [==============================] - 75s 299ms/step - loss: 0.5773 - accuracy: 0.7884 - val_loss: 0.7878 - val_accuracy: 0.7086\n",
      "Epoch 25/40\n",
      "248/248 [==============================] - 73s 289ms/step - loss: 0.5863 - accuracy: 0.7843 - val_loss: 1.2508 - val_accuracy: 0.6303\n",
      "Epoch 26/40\n",
      "248/248 [==============================] - 74s 296ms/step - loss: 0.5642 - accuracy: 0.7934 - val_loss: 1.1049 - val_accuracy: 0.6212\n",
      "Epoch 27/40\n",
      "248/248 [==============================] - 77s 306ms/step - loss: 0.5461 - accuracy: 0.7968 - val_loss: 0.8962 - val_accuracy: 0.6758\n",
      "Epoch 28/40\n",
      "248/248 [==============================] - 71s 280ms/step - loss: 0.5393 - accuracy: 0.7997 - val_loss: 0.9312 - val_accuracy: 0.6601\n",
      "Epoch 29/40\n",
      "248/248 [==============================] - 69s 274ms/step - loss: 0.5277 - accuracy: 0.8045 - val_loss: 0.9149 - val_accuracy: 0.6798\n",
      "Epoch 30/40\n",
      "248/248 [==============================] - 68s 271ms/step - loss: 0.5174 - accuracy: 0.8062 - val_loss: 1.0166 - val_accuracy: 0.6495\n",
      "Epoch 31/40\n",
      "248/248 [==============================] - 67s 264ms/step - loss: 0.4997 - accuracy: 0.8188 - val_loss: 1.0324 - val_accuracy: 0.6369\n",
      "Epoch 32/40\n",
      "248/248 [==============================] - 67s 267ms/step - loss: 0.4978 - accuracy: 0.8154 - val_loss: 0.9215 - val_accuracy: 0.6758\n",
      "Epoch 33/40\n",
      "248/248 [==============================] - 72s 285ms/step - loss: 0.4829 - accuracy: 0.8258 - val_loss: 1.0748 - val_accuracy: 0.6005\n",
      "Epoch 34/40\n",
      "248/248 [==============================] - 73s 288ms/step - loss: 0.4761 - accuracy: 0.8202 - val_loss: 0.9253 - val_accuracy: 0.7005\n",
      "Epoch 35/40\n",
      "248/248 [==============================] - 72s 287ms/step - loss: 0.4602 - accuracy: 0.8371 - val_loss: 1.0125 - val_accuracy: 0.6808\n",
      "Epoch 36/40\n",
      "248/248 [==============================] - 72s 286ms/step - loss: 0.4569 - accuracy: 0.8283 - val_loss: 0.7815 - val_accuracy: 0.7394\n",
      "Epoch 37/40\n",
      "248/248 [==============================] - 70s 278ms/step - loss: 0.4560 - accuracy: 0.8304 - val_loss: 1.1415 - val_accuracy: 0.6263\n",
      "Epoch 38/40\n",
      "248/248 [==============================] - 70s 277ms/step - loss: 0.4420 - accuracy: 0.8364 - val_loss: 1.1155 - val_accuracy: 0.6318\n",
      "Epoch 39/40\n",
      "248/248 [==============================] - 71s 281ms/step - loss: 0.4368 - accuracy: 0.8371 - val_loss: 1.2521 - val_accuracy: 0.6298\n",
      "Epoch 40/40\n",
      "248/248 [==============================] - 71s 283ms/step - loss: 0.4302 - accuracy: 0.8394 - val_loss: 0.6752 - val_accuracy: 0.7737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14945796380>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modified_resnet50_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "               \n",
    "modified_resnet50_model.fit(train_generator, \n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=40,\n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=len(validation_generator),\n",
    "   ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
